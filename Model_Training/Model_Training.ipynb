{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**EEG Classification Model training**\n"
      ],
      "metadata": {
        "id": "5ax5qXCJbviH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdyRttl8x0nU",
        "outputId": "230eb3c3-c14a-471a-fec9-f2764c9b4d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyedflib\n",
            "  Downloading pyEDFlib-0.1.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from pyedflib) (1.21.5)\n",
            "Installing collected packages: pyedflib\n",
            "Successfully installed pyedflib-0.1.28\n"
          ]
        }
      ],
      "source": [
        "pip install pyedflib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVeqqz05yBl5"
      },
      "outputs": [],
      "source": [
        "import pyedflib\n",
        "import numpy as np\n",
        "from scipy import signal"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Data From EDF File Format**"
      ],
      "metadata": {
        "id": "OfLyXubBcO8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrLc3YNNynlJ"
      },
      "outputs": [],
      "source": [
        "def load_signal_from_edffile(path):\n",
        "  f= pyedflib.EdfReader(path)\n",
        "  n = f.signals_in_file\n",
        "  signal_labels = f.getSignalLabels()\n",
        "  sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
        "  for i in np.arange(n):\n",
        "          sigbufs[i, :] = f.readSignal(i)\n",
        "  annotations = f.read_annotation()\n",
        "  f._close()\n",
        "  return sigbufs.transpose(), annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**\n",
        "\n",
        "Extracting data by:\n",
        "\n",
        "1. Fitering the signal between 5 and 45Hz.\n",
        "2. Extracting data from 0.5s before the action till 1s afterwards"
      ],
      "metadata": {
        "id": "YWF-ta0NcVXS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPOyJiNjyoP8"
      },
      "outputs": [],
      "source": [
        "def preprocessing(x, y):\n",
        "  b, a = signal.butter(5, 5/80, 'high')\n",
        "  x = signal.filtfilt(b,a,x)\n",
        "  b, a = signal.butter(5, 45/80, 'low')\n",
        "  x = signal.filtfilt(b,a,x)\n",
        "  data = np.zeros((29, 240, 64))\n",
        "  for t0 in range(1,30):\n",
        "    data[t0-1, :, :] = x[int(y[t0][0]/10000000*160-80):int(y[t0][0]/10000000*160+160),:]\n",
        "  u = data.mean(0).reshape((1,)+data.shape[1:])\n",
        "  o = np.maximum(data.std(0).reshape((1,)+data.shape[1:]), 1e-10)\n",
        "  data = (data - u)/o\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting Labels Data**"
      ],
      "metadata": {
        "id": "fHxh7Qu9cq6l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1tyd9CGz1Xq"
      },
      "outputs": [],
      "source": [
        "def get_label(y):\n",
        "  label = np.array([])\n",
        "  for i in range(1,30):\n",
        "    h = y[i][2].decode('utf-8')\n",
        "    if h == 'T0':\n",
        "      label = np.append(label, [0,0,1], axis=0)\n",
        "    if h == 'T1':\n",
        "      label = np.append(label, [0,1,0], axis=0)\n",
        "    if h == 'T2':\n",
        "      label = np.append(label, [1,0,0], axis=0)\n",
        "  label = label.reshape(29,3)\n",
        "  return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FSR-5nedtph"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "daata = scipy.io.loadmat('/content/drive/MyDrive/new_data.mat')\n",
        "data1 = daata['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jmvFF-ikClI"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "daata = scipy.io.loadmat('/content/drive/MyDrive/labels.mat')\n",
        "label = daata['labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Data**\n",
        "\n",
        "Extracting data only form the electrodes as per the 16-channel OpenBCI Headset"
      ],
      "metadata": {
        "id": "1EezNC6Ncvqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCWUphmPeR4k"
      },
      "outputs": [],
      "source": [
        "data = np.zeros((11281,240,16))\n",
        "for i in range(0,11281):\n",
        "  data[i,:,0] = data1[i,:,21]\n",
        "  data[i,:,1] = data1[i,:,23]\n",
        "  data[i,:,2] = data1[i,:,8]\n",
        "  data[i,:,3] = data1[i,:,12]\n",
        "  data[i,:,4] = data1[i,:,46]\n",
        "  data[i,:,5] = data1[i,:,54]\n",
        "  data[i,:,6] = data1[i,:,60]\n",
        "  data[i,:,7] = data1[i,:,62]\n",
        "  data[i,:,8] = data1[i,:,29]\n",
        "  data[i,:,9] = data1[i,:,37]\n",
        "  data[i,:,10] = data1[i,:,31]\n",
        "  data[i,:,11] = data1[i,:,35]\n",
        "  data[i,:,12] = data1[i,:,40]\n",
        "  data[i,:,13] = data1[i,:,41]\n",
        "  data[i,:,14] = data1[i,:,48]\n",
        "  data[i,:,15] = data1[i,:,52]\n",
        "data = (data+1)/2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(data)"
      ],
      "metadata": {
        "id": "Ms9-4ZXrb1c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxc70aCUiHXo"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import AveragePooling2D\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Making the CNN model**\n",
        "\n",
        "The model will have dimensions as per the \"EEGNet\" model.\n",
        "\n",
        "(Credits for this model go to hauke-d/cnn-eeg)"
      ],
      "metadata": {
        "id": "rk8jevhsc7JG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9wuBQ9CkJqA"
      },
      "outputs": [],
      "source": [
        "nchan = 16\n",
        "input_shape = (240, 16, 1)\n",
        "l1 = 0.02\n",
        "model = Sequential()\n",
        "model.add(Conv2D(40, (65, 1), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"same\", input_shape=input_shape))\n",
        "model.add(Conv2D(40, (1, nchan), activation=\"relu\", kernel_regularizer=regularizers.l1(l1), padding=\"valid\"))\n",
        "model.add(AveragePooling2D((25, 1), strides=(15, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(80, activation=\"relu\"))\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55E7pgkYkQIv"
      },
      "outputs": [],
      "source": [
        "model.fit(data_subject1.reshape(109, 240, 16,1), label, batch_size=4, epochs=18, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZjHHrCRRmCF",
        "outputId": "6a971509-7fc6-4070-b521-355932ff6055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: New_Model/assets\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}